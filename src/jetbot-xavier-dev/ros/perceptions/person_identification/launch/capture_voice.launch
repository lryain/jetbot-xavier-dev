<launch>
    <arg name="name"/>
    <arg name="neural_network_inference_type"/> <!-- Options: cpu, torch_gpu or trt_gpu -->
    <arg name="camera_2d_wide_enabled" default="false"/>

    <node pkg="audio_utils" type="capture_node" name="capture_node" output="screen">
        <param name="backend" value="pulse_audio"/>
        <param name="device" value="alsa_input.usb-SEEED_ReSpeaker_4_Mic_Array__UAC1.0_-00.multichannel-input"/>
        <param name="format" value="signed_32"/>
        <param name="channel_count" value="6"/>
        <param name="sampling_frequency" value="16000"/>
        <param name="frame_sample_count" value="1024"/>
        <param name="merge" value="false"/>
        <param name="gain" value="1.0"/>
        <param name="latency_us" value="64000"/>

        <remap from="audio_out" to="audio_input_before_odas_signed_32_16000"/>

        <rosparam param="channel_map">
            [front-left, front-right, rear-left, rear-right, front-center, lfe]
        </rosparam>
    </node>

    <node pkg="odas_ros" type="odas_server_node.py" name="odas_server_node">
        <param name="configuration_path" value="$(find t_top)/config/respeaker_usb_4_mic_array.cfg"/>
        <param name="frame_id" value="odas"/>

        <remap from="raw" to="audio_input_before_odas_signed_32_16000"/>
        <remap from="ssl" to="audio_ssl"/>
        <remap from="sst" to="audio_sst"/>
        <remap from="sss" to="audio_input_signed_16_16000"/>
    </node>

    <node pkg="audio_analyzer" type="audio_analyzer_node.py" name="audio_analyzer_node">
        <param name="inference_type" value="$(arg neural_network_inference_type)"/>
        <param name="interval" value="32000"/> <!-- Low quality audio-->
        <param name="voice_probability_threshold" value="0.5"/>
        <param name="class_probability_threshold" value="0.5"/>

        <remap from="audio_in" to="audio_input_signed_16_16000"/>
        <remap from="audio_in/filter_state" to="audio_analyzer/filter_state"/>
        <remap from="sst" to="audio_sst"/>
    </node>

    <node pkg="person_identification" type="capture_voice_node.py" name="capture_voice_node" output="screen">
        <param name="name" value="$(arg name)"/>
        <param name="mean_size" value="10"/>
    </node>
</launch>
